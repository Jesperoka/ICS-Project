{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0948b21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fa4bd8d97bff6552e9a43d012fac77d",
     "grade": false,
     "grade_id": "cell-80f04a0df76355c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 1.0 - Generate the datasets (0p)\n",
    "\n",
    "**Authors:** TomÃ¡s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "### Training data for tasks 1.1-1.4\n",
    "\n",
    "In order to train the model, we require data. Therefore, we generate images of the robot at various positions in its state space. \n",
    "At every position chosen in the state space, an RGB image with dimensions 32x32x3, is generated as observation data $x$ together with the corresponding robot state $s=(\\theta, \\dot{\\theta})$, where $\\theta = [\\theta_1, \\theta_2]$ are the link angles of the robot, and $\\dot{\\theta} = [\\dot{\\theta_1}, \\dot{\\theta_2}]$ are the link angular velocities of the robot. \n",
    "The angle $\\theta_1$ of link 1 and $\\theta_2$ of link 2 are both defined with respect to the right horizontal position (or x-axis), both are wrapped to the $[-\\pi, \\pi]$ domain. \n",
    "\n",
    "We also generate a test set, which are observations of the robot sampled at every $2^{\\circ}$, of the first link and at every $2^{\\circ}$ of the second link for every sample of the first, giving 32400 (180x180) observations. \n",
    "\n",
    "Run the cells below to generate the data needed for the problems in `task_1b_train_NN.ipynb`.\n",
    "\n",
    "**This notebook is not graded but is required for all tasks of problem 1.**\n",
    "\n",
    "**Please do __not__ include the datasets of Problem 1 in your final submission!** I.e. exclude the `source/problem_1/datasets` folder from your ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f46e6b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7346ebd03888faea14f2be6a5a24451",
     "grade": false,
     "grade_id": "cell-b0a5a308ba3ef411",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import jit, lax, random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import cv2\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from progressbar import progressbar\n",
    "from typing import Dict, Tuple\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.kinematics import forward_kinematics\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# folder to save the dataset to\n",
    "datasets_folder = Path(\"datasets\")\n",
    "datasets_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b6ae4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcdb6c49c8591cfa4b166ad76cc24a53",
     "grade": false,
     "grade_id": "cell-81c5e7055cab8f7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generating dataset of state images \n",
    "\n",
    "### Training data for tasks 1.1-1.4\n",
    "\n",
    "In order to train the model, we require data. Therefore, we generate images of the robot at various positions in its state space. \n",
    "At every position chosen in the state space, an RGB image with dimensions 32x32x3, is generated as observation data $x$ together with the corresponding robot state $s=(\\theta, \\dot{\\theta})$, where $\\theta = [\\theta_1, \\theta_2]$ are the link angles of the robot, and $\\dot{\\theta} = [\\dot{\\theta_1}, \\dot{\\theta_2}]$ are the link angular velocities of the robot. \n",
    "The angle $\\theta_1$ of link 1 and $\\theta_2$ of link 2 are both defined with respect to the right horizontal position (or x-axis), both are wrapped to the $[-\\pi, \\pi]$ domain. \n",
    "\n",
    "#### Training data\n",
    "\n",
    "The training data constists of 20,000 images of the robot with link angles that are randomly sampled from the state space. \n",
    "- The link angles are first sampled and saved into the dataset with the label `th_curr_ss` to be used later as the ground truth labels. \n",
    "- From these angles, the robot is rendered into the 32x32x3 RGB images. Link 1 is blue and link 2 is red.\n",
    "\n",
    "#### Test data\n",
    "We also generate a test set, which are again 32x32x3 image observations of the robot sampled at every $2^{\\circ}$, of the first link and at every $2^{\\circ}$ of the second link for every sample of the first, giving 32400 (180x180) observations. Having a test data set larger than the training set is unusual in practice as we want our model to have as much data to train on in practice. As this is a training excercise (for you and the neural networks :), we generate this large test set over the state space so you can fully analyse the performance of the trained Neural Networks.\n",
    "\n",
    "Run the cells below to generate the data needed for the problems in `task_1b_train_NN.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f4bbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ef934ce994ee30f5b7d79ea8df22de3",
     "grade": false,
     "grade_id": "cell-cc1df24ab91e26fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_test_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    initial_conditions: jnp.array,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    puts the robot angle and x-y joint position in the dataset\n",
    "    \"\"\"\n",
    "    num_ic = initial_conditions.shape[0]\n",
    "    _dataset[\"th_curr_ss\"] = _dataset[\"th_curr_ss\"].at[:].set(initial_conditions)\n",
    "\n",
    "    # Gets the robot elbow and end effector x-y coordinates from the 'forward_kinematics' function\n",
    "    def _for_loop_cart_fun(idx, _dataset: Dict):\n",
    "        _x_eb, _x = forward_kinematics(ROBOT_PARAMS, _dataset[\"th_curr_ss\"][idx])\n",
    "        _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[idx].set(_x_eb)\n",
    "        _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[idx].set(_x)\n",
    "        return _dataset\n",
    "\n",
    "    _dataset = lax.fori_loop(\n",
    "        lower=0, upper=num_ic, body_fun=_for_loop_cart_fun, init_val=_dataset\n",
    "    )\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5bbb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efcfdb6ff3724dfde3f051a8cafdfdcc",
     "grade": false,
     "grade_id": "cell-9e08a807e942bfe7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    This function calls the 'draw_robot' function to draw the image\n",
    "    of the robot at each given theta values and returns the given \n",
    "    dataset with these drawn images corresponding to given angles\n",
    "    \"\"\"\n",
    "    _dataset = draw_robot(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea38041",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b3a9fdc7e18a15b4d5364f832a8c43a",
     "grade": false,
     "grade_id": "cell-5ae302690b9a1219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset = draw_robot_snn(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760c34d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80f6ca8e13e85fdf4cf278eb947727ba",
     "grade": false,
     "grade_id": "cell-6517c41248cb3d25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set seed so everyone has the same \"random\" training dataset\n",
    "onp.random.seed(42)\n",
    "\n",
    "# simulation parameters\n",
    "num_samples_train = 20000\n",
    "img_size = 32\n",
    "\n",
    "# Sample the state space of -pi to pi for both robot links \n",
    "training_angles_sampled = onp.random.uniform(-onp.pi, onp.pi, [num_samples_train, 2])\n",
    "\n",
    "# Generate test data: 180 x 180 images to evenly cover the state space\n",
    "th1_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 90.0)\n",
    "th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 90.0)\n",
    "\n",
    "test_angles = jnp.array(jnp.meshgrid(th1_range, th2_range)).T.reshape(-1, 2)\n",
    "\n",
    "num_samples_test = len(th1_range) * len(th2_range)\n",
    "\n",
    "# initialise the train and test datasets with the appropriate sized arrays\n",
    "# for the link angles \"th_curr_ss\", x-y elbow position \"x_eb_ts\", \n",
    "# x-y end effector position \"x_ts\" and the rendered image of the \n",
    "# robot at \"th_curr_ss\"\n",
    "training_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_train, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "test_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_test, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "# input the initial values in the dataset\n",
    "training_dataset = save_test_data_to_dataset(training_dataset, training_angles_sampled)\n",
    "test_dataset = save_test_data_to_dataset(test_dataset, test_angles)\n",
    "\n",
    "print(\"Rendering images of the robot for the training set ...\")\n",
    "training_dataset = save_image_data_to_dataset(training_dataset, ROBOT_PARAMS)\n",
    "\n",
    "print(\"Rendering images of the robot for the test set ...\")\n",
    "test_dataset = save_image_data_to_dataset(test_dataset, ROBOT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fb11b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15279e5b8e2c3773b6c3ae5f036f4603",
     "grade": false,
     "grade_id": "cell-1b212ae7fb3bdbe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Now save the dataset to a file so we can access it in the notebook for tasks 1.1-1.4\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_train.npz\"), **training_dataset\n",
    ")\n",
    "jnp.savez(file=str(datasets_folder / \"dataset_double_pendulum_test.npz\"), **test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a9bcd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab6851a82a3ff8ed84f079b20152d42c",
     "grade": false,
     "grade_id": "cell-a80c2b186ed2b196",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_distribution(_theta):\n",
    "    bin_no = 20\n",
    "    heatmap, xedges, yedges = onp.histogram2d(_theta[:, 0], _theta[:, 1], bins=bin_no)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    plt.clf()\n",
    "    plt.imshow(heatmap.T, extent=extent)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Link 1 angles (rad)\")\n",
    "    plt.ylabel(\"Link 2 angles (rad)\")\n",
    "    plt.title(\"Heat map of sample frequency in the state space\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788355e",
   "metadata": {},
   "source": [
    "## Lets see what data we have got\n",
    "\n",
    "Run the cells below to see the distribution of the train and test data set angles over the state space. You can see the training set has a far higher number of samples in some areas compared to others while the test set is evenly spread out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of training samples in the state space\n",
    "data_distribution(training_dataset[\"th_curr_ss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the distribution of test samplesin the state space\n",
    "data_distribution(test_dataset[\"th_curr_ss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810fc30",
   "metadata": {},
   "source": [
    "\n",
    "Run the cells below to show what the rendered image of the robot actually looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the training dataset\n",
    "index = onp.random.randint(0, num_samples_train)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", training_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(training_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the test dataset\n",
    "index = onp.random.randint(0, 180 * 180)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", test_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(test_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456ecdc",
   "metadata": {},
   "source": [
    "## Generating simulated event-based dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee155a",
   "metadata": {},
   "source": [
    "A simulated event-based image of a double pendulum is generated in the following cell, which is used for the training part in task 1.5. We use the same framework as in the RGB image generation section in the previous steps. However, event-based data requires the image itself and its dynamic transformation in continuous time. Therefore, we need to generate more data than in the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560df61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_sim_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    _sim_idx: int,\n",
    "    _sim_ts: Dict[str, jnp.ndarray],\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset[\"th_curr_ss\"] = (\n",
    "        _dataset[\"th_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_curr_ss\"] = (\n",
    "        _dataset[\"th_d_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_d_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[_sim_idx].set(_sim_ts[\"x_eb_ts\"][0])\n",
    "    _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[_sim_idx].set(_sim_ts[\"x_ts\"][0])\n",
    "\n",
    "    # Windowed data for SNN\n",
    "    _dataset[\"th_window_snn\"] = (\n",
    "        _dataset[\"th_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_window_snn\"] = (\n",
    "        _dataset[\"th_d_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_d_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts_window_snn\"] = (\n",
    "        _dataset[\"x_eb_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_eb_ts\"])\n",
    "    )\n",
    "    _dataset[\"x_ts_window_snn\"] = (\n",
    "        _dataset[\"x_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_ts\"])\n",
    "    )\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "@jit\n",
    "def generate_data_point(ic, _rng, _t_ts):\n",
    "    \"\"\"\n",
    "    Generates a data point for the state of the robot from a given angle.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # for ic_idx in range(initial_conditions, 1):\n",
    "\n",
    "    _rng, subkey1, subkey2 = random.split(_rng, 3)\n",
    "\n",
    "    max_th_d = 1 * jnp.pi\n",
    "\n",
    "    _th_d_0 = onp.array([max_th_d, max_th_d])\n",
    "    _sim_ts = simulate_robot(rp=ROBOT_PARAMS, t_ts=_t_ts, th_0=ic, th_d_0=_th_d_0)\n",
    "    return _sim_ts, _rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6ef11",
   "metadata": {},
   "source": [
    "A train set and a test set are saved separately in the following cell. We could use the `train/test_th1/2_range` parameter to adjust the links' simulation range, which also affects the amount of generated data. Currently, it could generate 120 groups of training data and 120 groups of test data randomly. For each dataset, it contains 1010 continuous-time images, which will be used in the subsequent step of converting to event-based data. Due to the time-consuming steps of rendering and saving images (currently 15-20 minutes to generate two datasets), we do not recommend generating very large datasets or using larger image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random number generator\n",
    "key = random.PRNGKey(seed=42)\n",
    "\n",
    "# simulation parameters\n",
    "sim_duration = 5.05\n",
    "sim_dt = 5e-3\n",
    "img_size = 32\n",
    "# Since the big O is not good compared to the size of dataset,\n",
    "# Run this multiple times for different sections of the first link,\n",
    "# then bring them together in the training file.\n",
    "train_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "train_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "test_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "test_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "\n",
    "\n",
    "# initial_conditions = jnp.array([th_range, th_range])\n",
    "train_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(train_th1_range, train_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "test_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(test_th1_range, test_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# set global variables\n",
    "TRAIN_NUM_DATA = len(train_th1_range) * len(train_th2_range)\n",
    "TEST_NUM_DATA = len(test_th1_range) * len(test_th2_range)\n",
    "NUM_SNN_DATA = 5\n",
    "\n",
    "\n",
    "trainset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TRAIN_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, 1010, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "testset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TEST_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros((TEST_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TEST_NUM_DATA, 1010, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Generating simulation data for the SNN training set ...\")\n",
    "for sim_idx in progressbar(range(TRAIN_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(train_initial_conditions[sim_idx], key, t_ts)\n",
    "    trainset = save_sim_data_to_dataset_snn(trainset, sim_idx, sim_ts)\n",
    "    \n",
    "print(\"Generating simulation data for the SNN test set ...\")\n",
    "for sim_idx in progressbar(range(TEST_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(test_initial_conditions[sim_idx], key, t_ts)\n",
    "    testset = save_sim_data_to_dataset_snn(testset, sim_idx, sim_ts)\n",
    "\n",
    "print(\"Rendering images of the robot for the SNN training set ...\")\n",
    "trainset = save_image_data_to_dataset_snn(trainset, ROBOT_PARAMS)\n",
    "print(\"Rendering images of the robot for the SNN test set ...\")\n",
    "testset = save_image_data_to_dataset_snn(testset, ROBOT_PARAMS)\n",
    "\n",
    "print(f\"Start save the images to the file:\")\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\"), **trainset\n",
    ")\n",
    "jnp.savez(file=str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\"), **testset)\n",
    "print(f\"save successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8584a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a799a8e11b72cf694964cda1f283826e",
     "grade": false,
     "grade_id": "cell-153af02d145a72de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Transfer RGB image data into simulated event-based data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09415f",
   "metadata": {},
   "source": [
    "We got training and test set in the previous generation step. Each dataset contains 120 consecutive sets of still images. Each set contains 1010 images. In the following steps, we will use these static images to simulate event-based data.\n",
    "\n",
    "Event-based data can only capture pixel changes. We will compare every two consecutive images. If the pixel goes from dark to bright, the event data of the first channel is set to 1. Conversely, if the pixel goes from bright to dark, the second channel's event data is set to 1. To capture noticeable pixel changes, we sample these 1010 images at intervals of 10. Ultimately, we can get 101 static images, which means we will get 100 event-based data containing pixel changes. We use 20 as the time step for each event-based data. Finally, we could obtain five event-based data from each group. The size of generated event-based data is: `[time_step: 20, channels: 2, size: 32, size: 32]`. They could be fed directly to SNNs.\n",
    "\n",
    "These event-based data will be saved seperately in the files named `train` and `test` in .pt format. In the following steps, we will use `torch.load()` method to read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fa0e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98cc827f6e13951bf3472a8fd59daecb",
     "grade": false,
     "grade_id": "cell-7484fca329336081",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def trainset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TRAIN_NUM_DATA, NUM_SNN_DATA)\n",
    "    train_set_dir = datasets_folder / \"event_based_data\" / \"train\"\n",
    "    if train_set_dir.exists():\n",
    "        if os.path.getsize(train_set_dir) == 0:\n",
    "            os.removedirs(train_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(train_set_dir)\n",
    "    os.makedirs(train_set_dir)\n",
    "\n",
    "    divide_and_save_data(snn_data, velocity, TRAIN_NUM_DATA, NUM_SNN_DATA, train_set_dir)\n",
    "\n",
    "\n",
    "def testset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TEST_NUM_DATA, NUM_SNN_DATA)\n",
    "    test_set_dir = datasets_folder / \"event_based_data\" / \"test\"\n",
    "    if test_set_dir.exists():\n",
    "        if os.path.getsize(test_set_dir) == 0:\n",
    "            os.removedirs(test_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(test_set_dir)\n",
    "    os.makedirs(test_set_dir)\n",
    "\n",
    "    divide_and_save_data(snn_data, velocity, TEST_NUM_DATA, NUM_SNN_DATA, test_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140d314",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb0b2a8aaa2ca03a8396311b04737c1",
     "grade": false,
     "grade_id": "cell-33da2085f09fb401",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Transform RGB sequential images into event-based data\")\n",
    "trainset_transform_to_snn(datasets_folder)\n",
    "testset_transform_to_snn(datasets_folder)\n",
    "print(f\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b82bfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5e64eda7847079aa1a671b8039777d",
     "grade": false,
     "grade_id": "cell-9b995596da8c8a6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Show examples of SNN data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9994ee",
   "metadata": {},
   "source": [
    "Two examples of event-based data are printed as `.gif` in this section. The yellow and purple edges represent two channels in the event-based data. We can see how the pendulum changes during these 20 time steps. Therefore, the temporal characteristics of event-based data are implied in it. SNN will process this data in the form of recurrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063a181",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eea1fc4aa3274184f71aab63aec2dfff",
     "grade": false,
     "grade_id": "cell-a1e1686afbe08372",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print a random SNN data from the training dataset\n",
    "\n",
    "index = onp.random.randint(0, TRAIN_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"train\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_train_example.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab66178",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4753a68a495fdd4500c5e4973a738e2d",
     "grade": false,
     "grade_id": "cell-0d435bba5acb4302",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print a random SNN data from the test dataset\n",
    "\n",
    "index = onp.random.randint(0, TEST_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"test\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_test_example.gif\"))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
